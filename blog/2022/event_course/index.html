<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>
     DVS-Group   | 不一样的世界：事件相机初探 
</title>
<meta name="description" content="The main website of DVS-Group in Wuhan University by Prof. Lei Yu.
">

<!-- Open Graph -->

<meta property="og:site_name" content="The main website of DVS-Group in Wuhan University by Prof. Lei Yu.
" />
<meta property="og:type" content="object" />
<meta property="og:title" content="" />
<meta property="og:url" content="/blog/2022/event_course/" />
<meta property="og:description" content="不一样的世界：事件相机初探" />
<meta property="og:image" content="" /> 

<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<!-- <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> -->
<link rel="stylesheet" type="text/css" href="/assets/css/googlefonts.css">

<!-- Code Syntax Highlighting -->
<!-- <link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" /> -->
<link rel="stylesheet" href="/assets/css/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🔥</text></svg>"> 
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/blog/2022/event_course/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->
  

<!-- Valine Comment -->

    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>
    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
            
            <a class="navbar-brand title font-weight-lighter" href="/">
       DVS-Group
      </a> 
            <!-- Navbar Toggle -->
            <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
            <div class="collapse navbar-collapse text-right" id="navbarNav">
                <ul class="navbar-nav ml-auto flex-nowrap">
                    <!-- About -->
                    <li class="nav-item ">
                        <a class="nav-link" href="/">
              About
              
            </a>
                    </li>
                    
                    <!-- Other pages -->
                              
                    <li class="nav-item ">
                        <a class="nav-link" href="/members/">
                Members
                
              </a>
                    </li>
                      
                    <li class="nav-item ">
                        <a class="nav-link" href="/projects/">
                Projects
                
              </a>
                    </li>
                      
                    <li class="nav-item ">
                        <a class="nav-link" href="/publications/">
                Publications
                
              </a>
                    </li>
                      
                    <li class="nav-item ">
                        <a class="nav-link" href="/resources/">
                Resources
                
              </a>
                    </li>
                                
                </ul>
            </div>
        </div>
    </nav>

</header>

    <!-- Content -->

    <div class="container mt-5">
      


<div class="post" lang="zh">


  <header class="post-header">
    <h1 class="post-title">不一样的世界：事件相机初探</h1>
    <p class="post-meta">March 14, 2022 </p> 
  </header>

  <article class="post-content">
    <p>“动态视觉与感知”课题组（DVS-Group）将组织第一次事件相机暑期课程，内容包括事件相机原理、数据处理以及相关基础算法的介绍；同时，我们还将简单介绍脉冲神经网络的基础知识和简单应用。课程简单有趣，主要面向本校低年级本科生和组内刚入学0年级研究生，欢迎大家报名学习。</p>

<p><strong>若希望加入课程学习，请加QQ群：690959899.</strong></p>

<p><strong>时间</strong>: 2022.03.19—2022.04.23<br />
<strong>地点</strong>: （将在QQ群内实时公布）<br />
<strong>要求</strong>: 每堂课开课前，请按照要求配置好自己的电脑环境，如果有什么问题，可以在QQ群联系对应的老师。<br />
<strong>内容</strong>:</p>
<ul>
  <li><a href="#初识事件相机基于事件的视觉感知和处理">初识事件相机——基于事件的视觉感知和处理</a></li>
  <li><a href="#怎么玩事件相机之数据采集处理和显示">怎么玩——事件相机之数据采集、处理和显示</a></li>
  <li><a href="#相机校正和位姿估计">相机校正和位姿估计</a></li>
  <li><a href="#基于事件的图像去模糊">基于事件的图像去模糊</a></li>
  <li><a href="#深度学习之对抗生成网络卡通动漫头像生成">深度学习之对抗生成网络（卡通动漫头像生成）</a></li>
  <li><a href="#脉冲神经网络基础">脉冲神经网络基础</a></li>
  <li><a href="#相关资料">相关资料</a></li>
</ul>

<hr />

<h2 id="初识事件相机基于事件的视觉感知和处理">初识事件相机——基于事件的视觉感知和处理</h2>
<p><strong>主讲人：</strong><a href="/">余磊老师</a><br />
<strong>时间：</strong>3月19日下午14：30-15：30</p>

<p>事件相机是一种新体制的成像传感器，与传统RGB图像不同，它仅感知场景的亮度变化。事件相机的输出带有时间、位置和极性的事件点集，通过事件点集动态感知场景变化，具有高速、高动态和低功耗的特性。因此，在一些高速、高动态场景中具有非常高的应用价值。</p>
<div class="row">
    <div class="col-sm-5 mt-3 mt-md-0">
        <img class="rounded z-depth-1" height="180px" src="/assets/img/event_course/toy_example.gif" data-zoomable="" />
    </div>
    <div class="col-sm-7 mt-3 mt-md-0">
        <img class="rounded z-depth-1" height="180px" src="/assets/img/event_course/hspeed.gif" data-zoomable="" />
    </div>
</div>
<div class="caption">
    第一个动画为事件相机的原理示意（来自瑞士INI-RPG组）；第二个动画为基于事件的高速成像结果（来自ICCV2021论文）。
</div>
<p>自2018年底，我们成立了DVS-Group研究小组，专注于事件相机的理论和应用研究，重点解决如何利用事件相机融合提升普通相机在高速、高动态等极端条件下的成像和视觉感知能力。目前，DVS-Group已经在事件相机领域累计发表了10余篇学术论文，包括1篇视觉顶会CVPR的Best Paper Candidate。</p>

<p>本课程将重点介绍事件相机的基础知识，着重实际操作，希望能通过这一系列的课程让低年级本科生马上就能动手用事件相机进行有趣的实验，实现自己的想法。</p>

<p>Enjoy the world of Events!</p>

<hr />

<h2 id="怎么玩事件相机之数据采集处理和显示">怎么玩——事件相机之数据采集、处理和显示</h2>
<p><strong>主讲人：</strong><a href="/members/lw/">廖伟</a><br />
<strong>时间：</strong>3月19日下午15：30-18：00<br />
<strong>准备工作：</strong>建议在<a href="https://blog.csdn.net/wzyaiwl/article/details/109558146">Windows</a>或<a href="https://blog.csdn.net/ITBigGod/article/details/85690257">Ubuntu</a>系统下，安装Anaconda3，并创建包含numpy、opencv、dv、matplotlib以及一些其他基础库的python环境, 以及安装dv软件。</p>
<ul>
  <li>Python环境配置
    <ol>
      <li>创建dv环境<br />
在Windows系统中，启动Anaconda Prompt终端，或在Ubuntu系统的终端中输入以下指令
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda create <span class="nt">-n</span> dv <span class="nv">python</span><span class="o">=</span>3.6
</code></pre></div>        </div>
      </li>
      <li>激活环境
        <ul>
          <li>对于Windows系统，在Anaconda Prompt中输入
            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> conda activate dv
</code></pre></div>            </div>
          </li>
          <li>对于Ubuntu系统，在终端中输入
            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">source </span>activate dv
</code></pre></div>            </div>
          </li>
        </ul>
      </li>
      <li>安装必要的依赖包<br />
  在激活环境后，使用pip3指令安装一些依赖包
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  pip3 <span class="nb">install </span>numpy opencv-python dv matplotlib
</code></pre></div>        </div>
        <p>使用conda指令安装jupyter notebook</p>
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  conda <span class="nb">install </span>jupyter notebook
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
  <li>DV软件安装
    <ul>
      <li>在Windows下，通过该<a href="http://release.inivation.com/gui/latest-win-stable">链接</a>下载最新版本的dv软件并安装</li>
      <li>在Ubuntu 18.04系统中，在终端中使用以下命令进行安装
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  sudo add-apt-repository ppa:ubuntu-toolchain-r/test
  sudo add-apt-repository ppa:inivation-ppa/inivation-bionic
  sudo apt-get update
  sudo apt-get install dv-gui
</code></pre></div>        </div>
      </li>
      <li>在Ubuntu 20.04系统中，在终端中使用以下命令进行安装
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  sudo add-apt-repository ppa:inivation-ppa/inivation
  sudo apt-get update
  sudo apt-get install dv-gui
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="相机校正和位姿估计">相机校正和位姿估计</h2>
<p><strong>主讲人：</strong><a href="/members/lj/">刘健</a><br />
<strong>时间：</strong>3月26日下午15：00-17：30<br />
<strong>准备工作：</strong>建议在<a href="https://blog.csdn.net/wzyaiwl/article/details/109558146">Windows</a>或<a href="https://blog.csdn.net/ITBigGod/article/details/85690257">Ubuntu</a> 系统下，安装Anaconda3，并创建包含numpy、opencv、matplotlib以及一些其他基础库的python环境。</p>

<ul>
  <li>Python环境配置
    <ol>
      <li>创建dv环境 <br />
在Windows系统中，启动Anaconda Prompt终端，或在Ubuntu系统的终端中输入以下指令
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda create -n calibration python=3.8
</code></pre></div>        </div>
      </li>
      <li>激活环境
        <ul>
          <li>对于Windows系统，在Anaconda Prompt中输入
            <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda activate calibration
</code></pre></div>            </div>
          </li>
        </ul>
      </li>
      <li>安装必要的依赖包<br />
在激活环境后，使用pip指令安装一些依赖包
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install numpy opencv-python opencv-contrib-python matplotlib
</code></pre></div>        </div>
        <p>使用conda指令安装依赖包</p>
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda install yaml
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
  <li>
    <p>进入jupyter notebook</p>

    <ul>
      <li>在Windows或者在Ubuntu下，在终端中使用以下命令进入文件夹并启动jupyter notebook
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd training_courses
jupyter notebook
</code></pre></div>        </div>
        <hr />
      </li>
    </ul>
  </li>
</ul>

<h2 id="基于事件的图像去模糊">基于事件的图像去模糊</h2>
<p><strong>主讲人：</strong><a href="/members/wbs/">王碧杉</a><br />
<strong>时间：</strong>4月2日下午15：00-17：30<br />
<strong>准备工作：</strong>在windows或ubuntu系统下，安装matlab和Anaconda3。\</p>

<ul>
  <li>Python环境配置
    <ol>
      <li>创建运行eSL-Net的环境，创建名为eslnet的虚拟环境
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda create -n eslnet python=3.6
</code></pre></div>        </div>
      </li>
      <li>激活虚拟环境
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda activate eslnet
</code></pre></div>        </div>
      </li>
      <li>安装pytorch
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install torch&gt;=1.0.0 torchvision
</code></pre></div>        </div>
      </li>
      <li>安装依赖包
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install argparse numpy opencv-python scipy 
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
</ul>

<hr />

<h2 id="深度学习之对抗生成网络卡通动漫头像生成">深度学习之对抗生成网络（卡通动漫头像生成）</h2>
<p><strong>主讲人：</strong><a href="/members/zc/">张驰</a><br />
<strong>时间：</strong>4月9日下午15：00-17：30<br />
<strong>准备工作：</strong></p>

<ul>
  <li>Python环境配置
    <ol>
      <li>python3-3.7，不可超过 3.7 版本</li>
      <li>tensorflow-cpu == 1.14.0</li>
    </ol>
  </li>
  <li>安装依赖包
    <ol>
      <li>安装tensorflow 相关依赖包</li>
      <li>安装SciPy 依赖包</li>
      <li>安装pillow  依赖包
均可安装好 python 后，终端使用“pip install 包名”进行安装。</li>
    </ol>
  </li>
</ul>

<hr />

<h2 id="脉冲神经网络基础">脉冲神经网络基础</h2>
<p><strong>主讲人：</strong><a href="/members/zx/">张翔</a><br />
<strong>时间：</strong>4月16日下午15：00-17：30<br />
<strong>准备工作：</strong></p>

<ul>
  <li>
    <p>环境配置<br />
Linux系统：在windows10下<a href="https://www.cnblogs.com/masbay/p/10745170.html">安装</a>ubuntu双系统（选择安装ubuntu16.04)，在Ubuntu16.04下<a href="https://blog.csdn.net/He_9520/article/details/99714635">安装并配置</a>cuda10.1+cudnn。在Ubuntu系统下<a href="https://blog.csdn.net/ITBigGod/article/details/85690257">安装</a>Anaconda3，然后使用anaconda来<a href="https://zhuanlan.zhihu.com/p/92292882">创建</a>python独立的虚拟环境并安装Pytorch。</p>

    <p>创建名为py36，python版本为3.6的虚拟环境</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda create -n py36 python=3.6
</code></pre></div>    </div>

    <p>可以在指定环境下安装jupyter notebook用于编写和运行代码</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda install jupyter notebook
</code></pre></div>    </div>

    <p>Windows系统：在Windows系统下<a href="https://blog.csdn.net/baidu_22225919/article/details/82957508">安装</a>Anaconda，然后使用anaconda来创建python独立的虚拟环境并安装Pytorch，操作与Linux系统下基本一致（Linux系统下使用terminal即可，Windows下使用附带的Anaconda Prompt）。</p>
  </li>
  <li>
    <p>库的安装</p>

    <p>以下库的安装均是在py36虚拟环境下，首先激活py36虚拟环境</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda activate py36
</code></pre></div>    </div>

    <p>以下三个软件包是Nengo的依赖包：</p>

    <p>安装nengo、nengo-gui和nengo-dl</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install nengo nengo-gui nengo-dl
</code></pre></div>    </div>
  </li>
</ul>

<hr />
<h2 id="相关资料">相关资料</h2>

<ol>
  <li>DVS-Group事件相机相关论文：<a href="https://dvs-whu.cn/publications/">https://dvs-whu.cn/publications/</a></li>
  <li>Github汇总：<a href="https://github.com/uzh-rpg/event-based_vision_resources">https://github.com/uzh-rpg/event-based_vision_resources</a></li>
  <li>相关论文列表（按年份）：<a href="https://docs.google.com/spreadsheets/d/1_OBbSz10CkxXNDHQd-Mn_ui3OmymMFvm-lW316uvxy8/edit#gid=0">https://docs.google.com/spreadsheets/d/1_OBbSz10CkxXNDHQd-Mn_ui3OmymMFvm-lW316uvxy8/edit#gid=0</a></li>
  <li>相关课程：
    <ul>
      <li>Event-based Robot Vision  (Spring 2020) by Guillermo Gallego：<a href="https://sites.google.com/view/guillermogallego/teaching/event-based-robot-vision">https://sites.google.com/view/guillermogallego/teaching/event-based-robot-vision</a></li>
      <li>Bio-inspired Computer Vision  (Spring 2020) by Guillermo Gallego：<a href="https://sites.google.com/view/guillermogallego/teaching/bio-inspired-computer-vision">https://sites.google.com/view/guillermogallego/teaching/bio-inspired-computer-vision</a></li>
    </ul>
  </li>
  <li>相关研究团队：
    <ul>
      <li>瑞士INI-RPG团队：<a href="http://rpg.ifi.uzh.ch/research_dvs.html">http://rpg.ifi.uzh.ch/research_dvs.html</a></li>
      <li>北大黄老师团队：<a href="http://www.ai.pku.edu.cn/info/1139/1243.htm">http://www.ai.pku.edu.cn/info/1139/1243.htm</a></li>
      <li>北大CI组：<a href="http://ci.idm.pku.edu.cn/">http://ci.idm.pku.edu.cn/</a></li>
      <li>同济大学：<a href="https://ispc-group.github.io/">https://ispc-group.github.io/</a></li>
      <li>上海科技大学：<a href="https://mpl.sist.shanghaitech.edu.cn/">https://mpl.sist.shanghaitech.edu.cn/</a></li>
    </ul>
  </li>
  <li>事件相机相关公司：
    <ul>
      <li>芯仑光电（现在为豪威EVS部门）<a href="https://www.omnivision-group.com/#/technology-detail/px-technology?id=60501de6a1fa3323104d5800">https://www.omnivision-group.com/#/technology-detail/px-technology?id=60501de6a1fa3323104d5800</a></li>
      <li>iniVation: <a href="https://inivation.com">https://inivation.com</a></li>
      <li>Prophesee: <a href="https://www.prophesee.ai">https://www.prophesee.ai</a></li>
    </ul>
  </li>
  <li>类脑芯片相关公司：
    <ul>
      <li>SynSense科技：<a href="https://www.synsense-neuromorphic.com/zh/home-zh">https://www.synsense-neuromorphic.com/zh/home-zh</a></li>
      <li>Intel Loihi：<a href="https://www.intel.cn/content/www/cn/zh/research/neuromorphic-computing.html">https://www.intel.cn/content/www/cn/zh/research/neuromorphic-computing.html</a></li>
    </ul>
  </li>
  <li>事件相机专题研讨会：
    <ul>
      <li>3rd Event-based Vision 2021: <a href="https://tub-rip.github.io/eventvision2021/">https://tub-rip.github.io/eventvision2021/</a></li>
      <li>2nd Event-based Vision 2019: <a href="http://rpg.ifi.uzh.ch/CVPR19_event_vision_workshop.html">http://rpg.ifi.uzh.ch/CVPR19_event_vision_workshop.html</a></li>
      <li>1st Event-based Vision 2017: <a href="http://rpg.ifi.uzh.ch/ICRA17_event_vision_workshop.html">http://rpg.ifi.uzh.ch/ICRA17_event_vision_workshop.html</a></li>
    </ul>
  </li>
</ol>

  </article>


  

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2022 Lei  Yu.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
    Last updated: May 06, 2022.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  
<!-- Enable Tooltips -->
<script type="text/javascript">
$(function () {$('[data-toggle="tooltip"]').tooltip()})
</script>



<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
